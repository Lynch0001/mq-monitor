apiVersion: v1
kind: ConfigMap
metadata:
  name: mq-monitor-prometheus
  namespace: mq
data:
  mq_prometheus.yaml: |
    #
    # This is the section of the configuration file
    # that is common for all collectors. You must combine it
    # with the collector-specific portion from the relevant
    # subdirectory to create the complete configuration file.
    
    global:
      useObjectStatus: true
      useResetQStats: false
      usePublications: true
      logLevel: {{ .Values.config.logLevel }}
      metaprefix: ""
      pollInterval: 30s
      rediscoverInterval: 1h
      tzOffset: 0h
    
    connection:
      queueManager: {{ .Values.queueManager.name }}
      # You can point at a CCDT here. You probably will have to use this
      # for TLS client connections to a queue manager
      # ccdtUrl:
      connName: mq-ibm-mq(1414)
      channel: DEV.ADMIN.SVRCONN
      user: admin
      password: passw0rd

      # Which queue should be used as the template for replies from the qmgr. This will
      # usually be a QMODEL
      # replyQueue: SYSTEM.DEFAULT.MODEL.QUEUE
      # If 'replyQueue' is set to a QLOCAL, then you must also set
      #   replyQueue2: A.DIFFERENT.QLOCAL

      # Using durable subscriptions for queue metrics reduces the need for MAXHANDS to be increased.
      # Setting this to a non-empty value switches the collectors to use durable subs. And then the
      # replyQueue and replyQueue2 values MUST refer to distinct QLOCALs. The value of this attribute must be
      # unique for any collector program connecting to this queue manager
      # durableSubPrefix:

      # Maximum time (seconds) to wait for a status response from qmgr. 
      waitInterval: 3

    # "channels" is for all the traditional MQ channels including SVRCONNs. "amqpChannels" shows
    # status for the AMQP objects
    objects:
      queues:
        - APP.*
        - "!SYSTEM.*"
        - "!AMQ.*"
        - QM*
        - DEV*
      channels:
        - SYSTEM.*
        - TO.*
      topics:
      subscriptions:
    #    amqpChannels:
    #    - "*"
    
    # The "filters" section gives additional control over what is collected for various
    # object types. Some fields in here used to be in other sections, but those
    # attributes now give an error to force configurations to move to this model.
    filters:
      # Setting this to "true" reduces the unique sets of data in the database, at the cost of
      # hiding metrics from separate instances. 
      hideSvrConnJobname: false
      # Setting this to "true" shows all channels, not just those that have some kind of active status
      showInactiveChannels: false
      # Similar to the hideSvrJobname attribute, but for AMQP channels. Reduces the number of unique
      # elements when set to "true"
      hideAMQPClientId: false
      # The number of subscriptions can be reduced by selecting a subset of types. Set to "NONE" to 
      # ignore all published queue metrics (but still keeping all queue manager metrics). The set
      # shown here gives best balance for number of subscriptions and useful metrics. If this is an empty 
      # list, all queue metrics are collected.
      queueSubscriptionSelector:
        - PUT
        - GET
        - GENERAL
    
    # Collector-specific configuration will also need to be added here. Some of the sample build
    # scripts will concatenate default definitions from the cmd/mq_* directories.
      
    # This is the collector-specific piece of the configuration
    prometheus:
        port: {{ .Values.prometheus.port }}
        # We can constrain the http listener to a single adapter via the 'host' config. Default is
        # to bind to all local addresses
        # host: 1.2.3.4
        metricsPath: {{ .Values.prometheus.path }}
        namespace: {{ .Values.prometheus.namespace }}
        # We can also set keystore information if the Prometheus instance uses TLS to contact the collector
        # httpsKeyFile:  "server.key"
        # httpsCertFile: "server.crt"
        # Keep running even if the qmgr is not available - allows a "STOPPED" status to be
        # returned to the Prometheus server.
        keepRunning: true
        # How often to check the status and to attempt to reconnect if there's been a failure  
        reconnectInterval: 5s          
      
